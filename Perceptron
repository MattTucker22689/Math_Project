import pandas as pd
import math
import numpy as np
import torch
from torch import nn, optim
from torch.nn import functional as F
from torch.utils.data import TensorDataset, DataLoader
from sklearn.model_selection import train_test_split

LR = 1.5e-4
MAX_EPOCH = 200
BATCH_SIZE = 32
TERMS = 10
device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")


class PrimeTests(nn.Module):
    def __init__(self):
        super(PrimeTests, self).__init__()
        self.series_1 = nn.Sequential(nn.Linear(1, 512))
        self.series_2 = nn.Sequential(nn.Linear(512, 512))
        self.series_3 = nn.Sequential(nn.Linear(512, 1))
        self.series_full = nn.Sequential(nn.Linear(1, 512),     
                                 nn.ReLU(),
                                 nn.Linear(512, 512),
                                 nn.ReLU(),
                                 nn.Linear(512, 1), nn.ReLU())
        

    def forward(self, x):
        x = self.series_full(x)
        return x


old_name = 'full_solutions.csv'
primes = pd.read_csv(old_name, sep='\t')
primes = primes.drop(columns='Unnamed: 0')
x = primes.iloc[:, 0].values
y = primes.iloc[:, 1].values

X_train, X_val, y_train, y_val = map(torch.tensor, train_test_split(x, y, test_size=0.2))
train_dataloader = DataLoader(TensorDataset(X_train.unsqueeze(1), y_train.unsqueeze(1)), batch_size=BATCH_SIZE,
                              pin_memory=True, shuffle=True)
val_dataloader = DataLoader(TensorDataset(X_val.unsqueeze(1), y_val.unsqueeze(1)), batch_size=BATCH_SIZE,
                            pin_memory=True, shuffle=True)

model = PrimeTests().to(device)
optimizer = optim.Adam(model.parameters(), lr=LR)
criterion = nn.MSELoss(reduction="mean") # nn.L1Loss() #

# training loop
train_loss_list = list()
val_loss_list = list()
for epoch in range(MAX_EPOCH):
    print("epoch %d / %d" % (epoch + 1, MAX_EPOCH))
    model.train()
    # training loop
    temp_loss_list = list()
    for X_train, y_train in train_dataloader:
        X_train = X_train.type(torch.float32).to(device)
        y_train = y_train.type(torch.float32).to(device)

        optimizer.zero_grad()

        score = model(X_train)

        loss = criterion(score, y_train)
        # loss.requires_grad = True
        loss.backward()

        optimizer.step()

        temp_loss_list.append(loss.detach().cpu().numpy())

    temp_loss_list = list()
    for X_train, y_train in train_dataloader:
        X_train = X_train.type(torch.float32).to(device)
        y_train = y_train.type(torch.float32).to(device)

        score = model(X_train)

        loss = criterion(score, y_train)

        temp_loss_list.append(loss.detach().cpu().numpy())

    train_loss_list.append(np.average(temp_loss_list))

    # validation
    model.eval()

    temp_loss_list = list()
    for X_val, y_val in val_dataloader:
        X_val = X_val.type(torch.float32).to(device)
        y_val = y_val.type(torch.float32).to(device)

        score = model(X_val)

        loss = criterion(score, y_val)

        temp_loss_list.append(loss.detach().cpu().numpy())

    val_loss_list.append(np.average(temp_loss_list))

    print("\ttrain loss: %.5f" % train_loss_list[-1])
    print("\tval loss: %.5f" % val_loss_list[-1])
